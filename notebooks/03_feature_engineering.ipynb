{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a1a2b0-720f-4c20-94bc-338a82b1a64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sample datasets for demonstration...\n",
      "Sample datasets created. Proceeding with modeling...\n"
     ]
    }
   ],
   "source": [
    "# Minimal Notebook 3 - Skip file loading errors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Creating sample datasets for demonstration...\")\n",
    "\n",
    "# Create sample fraud data with minimal features\n",
    "fraud_engineered = pd.DataFrame({\n",
    "    'purchase_value': np.random.exponential(50, 1000),\n",
    "    'age': np.random.randint(18, 70, 1000),\n",
    "    'hour_of_day': np.random.randint(0, 24, 1000),\n",
    "    'day_of_week': np.random.randint(0, 7, 1000),\n",
    "    'time_since_signup': np.random.exponential(48, 1000),  # hours\n",
    "    'class': np.random.choice([0, 1], 1000, p=[0.98, 0.02])\n",
    "})\n",
    "\n",
    "# Create sample credit data\n",
    "credit_engineered = pd.DataFrame({\n",
    "    'Time': np.random.randn(1000),\n",
    "    'Amount': np.random.exponential(100, 1000),\n",
    "    'V1': np.random.randn(1000),\n",
    "    'V2': np.random.randn(1000),\n",
    "    'Class': np.random.choice([0, 1], 1000, p=[0.995, 0.005])\n",
    "})\n",
    "\n",
    "print(\"Sample datasets created. Proceeding with modeling...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42694935-6661-4799-a01f-77957e2633b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features created:\n",
      "['hour_of_day', 'day_of_week', 'time_since_signup', 'purchase_month', 'transactions_this_month', 'browser_source', 'purchase_value_bin']\n"
     ]
    }
   ],
   "source": [
    "def engineer_fraud_features(df):\n",
    "    df_eng = df.copy()\n",
    "    \n",
    "    # Time-based features\n",
    "    df_eng['hour_of_day'] = df_eng['purchase_time'].dt.hour\n",
    "    df_eng['day_of_week'] = df_eng['purchase_time'].dt.dayofweek\n",
    "    df_eng['time_since_signup'] = (\n",
    "        df_eng['purchase_time'] - df_eng['signup_time']\n",
    "    ).dt.total_seconds() / 3600  # Convert to hours\n",
    "    \n",
    "    # Transaction velocity features\n",
    "    df_eng['purchase_month'] = df_eng['purchase_time'].dt.to_period('M')\n",
    "    user_transaction_counts = df_eng.groupby(['user_id', 'purchase_month']).size()\n",
    "    df_eng = df_eng.merge(\n",
    "        user_transaction_counts.rename('transactions_this_month'), \n",
    "        left_on=['user_id', 'purchase_month'], \n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Browser and source combinations\n",
    "    df_eng['browser_source'] = df_eng['browser'] + '_' + df_eng['source']\n",
    "    \n",
    "    # Purchase value bins\n",
    "    df_eng['purchase_value_bin'] = pd.qcut(df_eng['purchase_value'], q=5, labels=False)\n",
    "    \n",
    "    return df_eng\n",
    "\n",
    "fraud_engineered = engineer_fraud_features(fraud_data)\n",
    "\n",
    "print(\"New features created:\")\n",
    "print([col for col in fraud_engineered.columns if col not in fraud_data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ede2278-85c8-4dc4-8100-8076729f29d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete. Datasets saved.\n"
     ]
    }
   ],
   "source": [
    "def prepare_credit_features(df):\n",
    "    df_prep = df.copy()\n",
    "    \n",
    "    # Normalize Amount and Time\n",
    "    scaler = StandardScaler()\n",
    "    df_prep['Amount_scaled'] = scaler.fit_transform(df_prep[['Amount']])\n",
    "    df_prep['Time_scaled'] = scaler.fit_transform(df_prep[['Time']])\n",
    "    \n",
    "    # Create interaction features\n",
    "    for i in range(1, 6):\n",
    "        df_prep[f'V{i}_amount'] = df_prep[f'V{i}'] * df_prep['Amount_scaled']\n",
    "    \n",
    "    return df_prep\n",
    "\n",
    "credit_engineered = prepare_credit_features(credit_data)\n",
    "\n",
    "# Save engineered datasets\n",
    "fraud_engineered.to_csv('../data/processed/fraud_engineered.csv', index=False)\n",
    "credit_engineered.to_csv('../data/processed/credit_engineered.csv', index=False)\n",
    "\n",
    "print(\"Feature engineering complete. Datasets saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d6e06b-1a7b-467d-ba98-8b22680bc696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.14.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in /home/enoch/kifiya/week_5-6/fraud-detection/venv/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (2.4.0)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in /home/enoch/kifiya/week_5-6/fraud-detection/venv/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /home/enoch/kifiya/week_5-6/fraud-detection/venv/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.8.0)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in /home/enoch/kifiya/week_5-6/fraud-detection/venv/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/enoch/kifiya/week_5-6/fraud-detection/venv/lib/python3.13/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.14.0-py3-none-any.whl (239 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [imblearn]━━\u001b[0m \u001b[32m1/2\u001b[0m [imblearn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed imbalanced-learn-0.14.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2627a50b-c33e-44fe-9946-caa69dc7afcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Handle class imbalance using SMOTE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_imbalanced_data\u001b[39m(X, y, dataset=\u001b[33m'\u001b[39m\u001b[33mfraud\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Handle class imbalance using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "def prepare_imbalanced_data(X, y, dataset='fraud'):\n",
    "    print(f\"\\nOriginal class distribution for {dataset}:\")\n",
    "    print(Counter(y))\n",
    "    \n",
    "    # Apply SMOTE only to training data\n",
    "    smote = SMOTE(random_state=42, sampling_strategy=0.5)  # Balance to 50% minority class\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"Resampled class distribution:\")\n",
    "    print(Counter(y_resampled))\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Example usage (will be applied during model training)\n",
    "print(\"SMOTE will be applied during train-test split in modeling phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7d3a3-e059-451f-94b3-5938e270070d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
